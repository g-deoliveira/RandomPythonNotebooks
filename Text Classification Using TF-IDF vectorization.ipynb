{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification Using TF-IDF\n",
    "The dataset consists of 2225 documents from the BBC news website corresponding to stories in five topical areas from 2004-2005.\n",
    "\n",
    "* business\n",
    "* entertainment\n",
    "* politics\n",
    "* sport\n",
    "* tech\n",
    "\n",
    "Downloaded from here: http://mlg.ucd.ie/datasets/bbc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/Users/guilhermede-oliveira/Library/DataScienceStudio/dss_design_v5/managed_folders/BBCARTICLES/hZFXEdPS/BBC'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/guilhermede-oliveira/Library/DataScienceStudio/dss_design_v5/managed_folders/BBCARTICLES/hZFXEdPS/BBC/entertainment\n",
      "386\n",
      "/Users/guilhermede-oliveira/Library/DataScienceStudio/dss_design_v5/managed_folders/BBCARTICLES/hZFXEdPS/BBC/business\n",
      "510\n",
      "/Users/guilhermede-oliveira/Library/DataScienceStudio/dss_design_v5/managed_folders/BBCARTICLES/hZFXEdPS/BBC/sport\n",
      "511\n",
      "/Users/guilhermede-oliveira/Library/DataScienceStudio/dss_design_v5/managed_folders/BBCARTICLES/hZFXEdPS/BBC/politics\n",
      "417\n",
      "/Users/guilhermede-oliveira/Library/DataScienceStudio/dss_design_v5/managed_folders/BBCARTICLES/hZFXEdPS/BBC/README.TXT\n",
      "/Users/guilhermede-oliveira/Library/DataScienceStudio/dss_design_v5/managed_folders/BBCARTICLES/hZFXEdPS/BBC/tech\n",
      "401\n",
      "(2225, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file_name</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>[Gallery unveils interactive tree\\n, \\n, A Chr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>[Jarre joins fairytale celebration\\n, \\n, Fren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>[Musical treatment for Capra film\\n, \\n, The c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label file_name                                           raw_text\n",
       "0  entertainment   001.txt  [Gallery unveils interactive tree\\n, \\n, A Chr...\n",
       "1  entertainment   002.txt  [Jarre joins fairytale celebration\\n, \\n, Fren...\n",
       "2  entertainment   003.txt  [Musical treatment for Capra film\\n, \\n, The c..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load articles into a Pandas DataFrame\n",
    "\n",
    "#path = '/Users/guilhermede-oliveira/Library/DataScienceStudio/dss_design_v5/managed_folders/BBCARTICLES/hZFXEdPS/BBC'\n",
    "\n",
    "results = []\n",
    "for article_class in os.listdir(root_path):\n",
    "    folder_path = os.path.join(root_path, article_class)\n",
    "    print folder_path\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    else:\n",
    "        #print article_class, path\n",
    "        articles = os.listdir(folder_path)\n",
    "        print len(articles)\n",
    "        for article in sorted(articles):\n",
    "            #print article\n",
    "            article_path = os.path.join(folder_path, article)\n",
    "            #print article_path\n",
    "            with open(article_path, 'r') as f:\n",
    "                text = f.readlines()\n",
    "            #print text\n",
    "            results.append([article_class, article, text])\n",
    "\n",
    "df = pd.DataFrame(results, columns=['label', 'file_name', 'raw_text'])\n",
    "print df.shape\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n"
     ]
    }
   ],
   "source": [
    "# load each article into a variable X, perform some preprocessing, ie\n",
    "# remove line-breaks ('\\n')\n",
    "# this is an area where a lot of additional preprocessing could be added\n",
    "# for instance you could remove numbers, extra spaces, etc...\n",
    "X = df['raw_text'].values\n",
    "X = [' '.join(x).replace('\\n', '') for x in X]\n",
    "print len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'politics': 3, 'sport': 2, 'tech': 4, 'business': 1, 'entertainment': 0}\n"
     ]
    }
   ],
   "source": [
    "# encode the labels into the y-variable\n",
    "labels = df['label'].unique().tolist()\n",
    "labels = {label:k for k,label in enumerate(labels)}\n",
    "print labels\n",
    "y = df['label'].map(labels).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225, 1852)\n"
     ]
    }
   ],
   "source": [
    "# in the TF-IDF below, we are getting rid of english stop words, we are considering unigrams and bigrams, \n",
    "# we are pruning the dictionary (max_df, min_df), and we are ignoring decoding errors\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=0.8, min_df=40, decode_error='ignore')\n",
    "\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "print X_vectorized.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'000', u'000 people', u'10', u'100', u'100 000', u'100m', u'11', u'12', u'12 months', u'13', u'14', u'15', u'150', u'16', u'17', u'18', u'19', u'1980s', u'1990s', u'1994', u'1997', u'1998', u'1999', u'1bn', u'1m', u'20', u'200', u'2000', u'2001', u'2002', u'2003', u'2004', u'2005', u'2006', u'2007', u'21', u'22', u'23', u'24', u'25', u'26', u'27', u'28', u'29', u'2bn', u'30', u'300', u'31', u'32', u'34', u'35', u'36', u'3bn', u'40', u'45', u'48', u'4bn', u'4m', u'50', u'500', u'5bn', u'5m', u'60', u'6bn', u'70', u'75', u'80', u'8bn', u'90', u'ability', u'able', u'abroad', u'absolutely', u'academy', u'accept', u'accepted', u'access', u'according', u'account', u'accounts', u'accused', u'achieved', u'act', u'acting', u'action', u'actions', u'activity', u'actor', u'actress', u'actually', u'add', u'added', u'adding', u'address', u'administration', u'admitted', u'advantage', u'affairs', u'affected', u'africa']\n"
     ]
    }
   ],
   "source": [
    "# these are the first 100 tokens in the vectorized documents\n",
    "print vectorizer.get_feature_names()[:100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## Train/Validation Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225, 1852)\n",
      "(1891, 1852) (1891,)\n",
      "(334, 1852) (334,)\n"
     ]
    }
   ],
   "source": [
    "# split the data into a training/test set and a validation set\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_vectorized, y, test_size=0.15, random_state=42)\n",
    "\n",
    "print X_vectorized.shape\n",
    "print X_train.shape, y_train.shape\n",
    "print X_val.shape, y_val.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Random Forest Classifier Using Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid='warn', n_jobs=None,\n",
      "       param_grid={'n_estimators': [100], 'min_samples_split': [10, 20, 40], 'criterion': ['gini', 'entropy'], 'max_depth': [3, 6, 9, 12, 15], 'min_samples_leaf': [10, 20, 40]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "params = {\"n_estimators\":[100],\n",
    "          \"max_depth\": [3, 6, 9, 12, 15],\n",
    "          \"min_samples_split\": [10, 20, 40],\n",
    "          \"criterion\": [\"gini\", \"entropy\"],\n",
    "          \"min_samples_leaf\": [10, 20, 40]\n",
    "         }\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rfc, param_grid=params, cv=3)\n",
    "print grid_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [100], 'min_samples_split': [10, 20, 40], 'criterion': ['gini', 'entropy'], 'max_depth': [3, 6, 9, 12, 15], 'min_samples_leaf': [10, 20, 40]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_vectorized, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 20, 'n_estimators': 100, 'criterion': 'entropy', 'max_depth': 12, 'min_samples_leaf': 10}\n"
     ]
    }
   ],
   "source": [
    "print grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.917752808988764\n"
     ]
    }
   ],
   "source": [
    "print grid_search.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance on the Validation Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the model to the validation set\n",
    "\n",
    "y_pred = grid_search.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334,) (334,)\n",
      "321\n"
     ]
    }
   ],
   "source": [
    "print y_pred.shape, y_val.shape\n",
    "print sum(y_pred == y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9550898203592815"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this means out of 334 records in the validation set, 319 were predicted correctly\n",
    "319/334."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write pickled model and model parameters to Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/guilhermede-oliveira/Documents/Columbia/Fall 2018 - Capstone/Text Classification/random_forest_classifier.pkl\n",
      "/Users/guilhermede-oliveira/Documents/Columbia/Fall 2018 - Capstone/Text Classification/model_parameters.json\n"
     ]
    }
   ],
   "source": [
    "model_path = '/Users/guilhermede-oliveira/Documents/Columbia/Fall 2018 - Capstone/Text Classification'\n",
    "\n",
    "pickle_file_path = os.path.join(model_path, 'random_forest_classifier.pkl')\n",
    "param_file_path = os.path.join(model_path, 'model_parameters.json')\n",
    "\n",
    "print pickle_file_path\n",
    "print param_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = grid_search.best_estimator_\n",
    "model_parameters = predictor.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/guilhermede-oliveira/Documents/Columbia/Fall 2018 - Capstone/Text Classification/random_forest_classifier.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write pickled model to folder\n",
    "joblib.dump(predictor, pickle_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write model paramters to folder\n",
    "with open(param_file_path, 'w') as fp:\n",
    "    json.dump(model_parameters, fp, sort_keys=True, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00129982, 0.        , 0.0003993 , ..., 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame(predictor.feature_importances_,\n",
    "                  index = vectorizer.get_feature_names(),\n",
    "                  columns=['importance']).sort_values('importance',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1852, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mr</th>\n",
       "      <td>mr</td>\n",
       "      <td>0.036499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market</th>\n",
       "      <td>market</td>\n",
       "      <td>0.028711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>government</th>\n",
       "      <td>government</td>\n",
       "      <td>0.028004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>game</th>\n",
       "      <td>game</td>\n",
       "      <td>0.024744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>users</th>\n",
       "      <td>users</td>\n",
       "      <td>0.022529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature  importance\n",
       "mr                  mr    0.036499\n",
       "market          market    0.028711\n",
       "government  government    0.028004\n",
       "game              game    0.024744\n",
       "users            users    0.022529"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi['feature'] = fi.index\n",
    "fi = fi[['feature', 'importance']]\n",
    "print fi.shape\n",
    "\n",
    "fi.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells us the tokens in the text that had the most important effect on the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
